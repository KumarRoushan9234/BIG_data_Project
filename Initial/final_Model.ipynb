{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9d71bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import unix_timestamp, col\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8627c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"CreditCardFraudDetection\").getOrCreate()\n",
    "fraudTrain = spark.read.csv(\"fraudTrain.csv\", header=True, inferSchema=True)\n",
    "fraudTest = spark.read.csv(\"fraudTest.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fadf2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['_c0', 'cc_num', 'first', 'last', 'gender', 'street', 'city', 'state',\n",
    "             'zip', 'job', 'dob', 'trans_num', 'merchant']\n",
    "fraudTrain = fraudTrain.drop(*drop_cols)\n",
    "fraudTest = fraudTest.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4d55485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTrain = fraudTrain.withColumn(\"trans_date_ts\", unix_timestamp(\"trans_date_trans_time\")).drop(\"trans_date_trans_time\")\n",
    "fraudTest = fraudTest.withColumn(\"trans_date_ts\", unix_timestamp(\"trans_date_trans_time\")).drop(\"trans_date_trans_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "765512e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTrain = fraudTrain.filter(fraudTrain[\"category\"].isNotNull()) \n",
    "# Remove rows with null values in \"category\"\n",
    "fraudTest = fraudTest.filter(fraudTest[\"category\"].isNotNull())  \n",
    "# Remove rows with null values in \"category\"\n",
    "\n",
    "# Fill missing values in \"category\" with \"unknown\" if necessary\n",
    "fraudTrain = fraudTrain.fillna({\"category\": \"unknown\"})\n",
    "fraudTest = fraudTest.fillna({\"category\": \"unknown\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "411c1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure \"category\" column is of string type\n",
    "fraudTrain = fraudTrain.withColumn(\"category\", col(\"category\").cast(\"string\"))\n",
    "fraudTest = fraudTest.withColumn(\"category\", col(\"category\").cast(\"string\"))\n",
    "\n",
    "# String Indexing\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"category_index\", handleInvalid=\"skip\")\n",
    "indexer_model = indexer.fit(fraudTrain)\n",
    "fraudTrain = indexer_model.transform(fraudTrain)\n",
    "fraudTest = indexer_model.transform(fraudTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4c88b64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of fraudTrain dataset:\n",
      "root\n",
      " |-- category: string (nullable = false)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      " |-- trans_date_ts: long (nullable = true)\n",
      " |-- category_index: double (nullable = false)\n",
      "\n",
      "Sample rows from fraudTrain:\n",
      "+-------------+------+-------+---------+--------+----------+------------------+-----------+--------+-------------+--------------+\n",
      "|     category|   amt|    lat|     long|city_pop| unix_time|         merch_lat| merch_long|is_fraud|trans_date_ts|category_index|\n",
      "+-------------+------+-------+---------+--------+----------+------------------+-----------+--------+-------------+--------------+\n",
      "|     misc_net|  4.97|36.0788| -81.1781|    3495|1325376018|         36.011293| -82.048315|       0|   1546281018|          11.0|\n",
      "|  grocery_pos|107.23|48.8878|-118.2105|     149|1325376044|49.159046999999994|-118.186462|       0|   1546281044|           1.0|\n",
      "|entertainment|220.11|42.1808| -112.262|    4154|1325376051|         43.150704|-112.154481|       0|   1546281051|           6.0|\n",
      "|gas_transport|  45.0|46.2306|-112.1138|    1939|1325376076|         47.034331|-112.561071|       0|   1546281076|           0.0|\n",
      "|     misc_pos| 41.96|38.4207| -79.4629|      99|1325376186|         38.674999| -78.632459|       0|   1546281186|          10.0|\n",
      "+-------------+------+-------+---------+--------+----------+------------------+-----------+--------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Summary statistics:\n",
      "+-------+-----------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+\n",
      "|summary|              amt|              lat|              long|         city_pop|           unix_time|         merch_lat|        merch_long|\n",
      "+-------+-----------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+\n",
      "|  count|          1296675|          1296675|           1296675|          1296675|             1296675|           1296675|           1296675|\n",
      "|   mean|70.35103545607046|38.53762161490217|-90.22633537864573|88824.44056297839|1.3492436367261226E9|38.537338044699666|-90.22646479897256|\n",
      "| stddev|160.3160385715277|5.075808438803937|13.759076946486305|301956.3606887509|1.2841278423361162E7|  5.10978836967917|13.771090564792418|\n",
      "|    min|              1.0|          20.0271|         -165.6723|               23|          1325376018|         19.027785|       -166.671242|\n",
      "|    max|          28948.9|          66.6933|          -67.9503|          2906700|          1371816817|         67.510267|        -66.950902|\n",
      "+-------+-----------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Schema of fraudTrain dataset:\")\n",
    "fraudTrain.printSchema()\n",
    "\n",
    "print(\"Sample rows from fraudTrain:\")\n",
    "fraudTrain.show(5)\n",
    "\n",
    "print(\"Summary statistics:\")\n",
    "fraudTrain.select(\"amt\", \"lat\", \"long\", \"city_pop\", \"unix_time\", \"merch_lat\", \"merch_long\").describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c81c4276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of fraudTest dataset:\n",
      "root\n",
      " |-- category: string (nullable = false)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      " |-- trans_date_ts: long (nullable = true)\n",
      " |-- category_index: double (nullable = false)\n",
      "\n",
      "Sample rows from fraudTrain:\n",
      "+--------------+-----+-------+------------------+--------+----------+------------------+-----------+--------+-------------+--------------+\n",
      "|      category|  amt|    lat|              long|city_pop| unix_time|         merch_lat| merch_long|is_fraud|trans_date_ts|category_index|\n",
      "+--------------+-----+-------+------------------+--------+----------+------------------+-----------+--------+-------------+--------------+\n",
      "| personal_care| 2.86|33.9659|          -80.9355|  333497|1371816865|         33.986391| -81.200714|       0|   1592721865|           8.0|\n",
      "| personal_care|29.84|40.3207|          -110.436|     302|1371816873|39.450497999999996|-109.960431|       0|   1592721873|           8.0|\n",
      "|health_fitness|41.28|40.6729|          -73.5365|   34496|1371816893|          40.49581| -74.196111|       0|   1592721893|           9.0|\n",
      "|      misc_pos|60.05|28.5697|          -80.8191|   54767|1371816915|28.812397999999998| -80.883061|       0|   1592721915|          10.0|\n",
      "|        travel| 3.19|44.2529|-85.01700000000001|    1126|1371816917|         44.959148| -85.884734|       0|   1592721917|          13.0|\n",
      "+--------------+-----+-------+------------------+--------+----------+------------------+-----------+--------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Summary statistics:\n",
      "+-------+------------------+------------------+------------------+------------------+--------------------+------------------+------------------+\n",
      "|summary|               amt|               lat|              long|          city_pop|           unix_time|         merch_lat|        merch_long|\n",
      "+-------+------------------+------------------+------------------+------------------+--------------------+------------------+------------------+\n",
      "|  count|            555719|            555719|            555719|            555719|              555719|            555719|            555719|\n",
      "|   mean| 69.39281023322945|38.543252821300456|-90.23132507832291| 88221.88791817447|1.3806788651667802E9|38.542797778038896|-90.23138049244679|\n",
      "| stddev|156.74594135531495| 5.061336211107398|13.721779747818564|300390.89206099446|   5201104.065917704| 5.095829265180013|13.733070748105233|\n",
      "|    min|               1.0|           20.0271|         -165.6723|                23|          1371816865|         19.027422|       -166.671575|\n",
      "|    max|          22768.11|           65.6899|          -67.9503|           2906700|          1388534374| 66.67929699999999|        -66.952026|\n",
      "+-------+------------------+------------------+------------------+------------------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Schema of fraudTest dataset:\")\n",
    "fraudTest.printSchema()\n",
    "\n",
    "print(\"Sample rows from fraudTrain:\")\n",
    "fraudTest.show(5)\n",
    "\n",
    "print(\"Summary statistics:\")\n",
    "fraudTest.select(\"amt\", \"lat\", \"long\", \"city_pop\", \"unix_time\", \"merch_lat\", \"merch_long\").describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a0685423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Feature Assembly\n",
    "features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long', 'trans_date_ts', 'category_index']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "fraudTrain = assembler.transform(fraudTrain).select(\"features\", \"is_fraud\")\n",
    "fraudTest = assembler.transform(fraudTest).select(\"features\", \"is_fraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7abc9",
   "metadata": {},
   "source": [
    "Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cfb0c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model\n",
      "Coefficients: [0.00280212298826414,0.04026609966050056,0.007865715632323522,8.71519358046513e-08,-4.521840406740288e-06,-0.03181115584332793,-0.00585068198450549,4.512287057236062e-06,-0.07032644543383682]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"is_fraud\", featuresCol=\"features\")\n",
    "lr_model = lr.fit(fraudTrain)\n",
    "print(\"Logistic Regression model\")\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4cbb9c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "Feature Importances: (9,[0,1,2,3,4,5,6,7,8],[0.7023911121238602,0.004562638595043176,0.004332124798876209,0.019919338772241894,0.005351964862438715,0.004415761895131943,0.0046105451822584425,0.00658888309617735,0.24782763067397245])\n",
      "Number of Trees: 50\n",
      "Max Depth: <bound method _DecisionTreeParams.getMaxDepth of RandomForestClassificationModel: uid=RandomForestClassifier_6d7e2f05ffd0, numTrees=50, numClasses=2, numFeatures=9>\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"is_fraud\", featuresCol=\"features\", numTrees=50)\n",
    "rf_model = rf.fit(fraudTrain)\n",
    "print(\"Random Forest model\")\n",
    "print(\"Feature Importances: \" + str(rf_model.featureImportances))\n",
    "print(\"Number of Trees: \" + str(rf_model.getNumTrees))\n",
    "print(\"Max Depth: \" + str(rf_model.getMaxDepth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6afa80d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Trees model\n",
      "Feature Importances: (9,[0,1,2,3,4,5,6,8],[0.44429708009183283,0.01654912615240762,0.017842684240530222,0.0880958532011804,0.02934285389356067,0.0014005439564304413,0.004885449859245977,0.3975864086048118])\n",
      "Number of Trees: 20\n",
      "Max Depth: <bound method _DecisionTreeParams.getMaxDepth of GBTClassificationModel: uid = GBTClassifier_bf98a93d79d7, numTrees=20, numClasses=2, numFeatures=9>\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(labelCol=\"is_fraud\", featuresCol=\"features\", maxIter=20)\n",
    "gbt_model = gbt.fit(fraudTrain)\n",
    "print(\"Gradient Boosted Trees model\")\n",
    "print(\"Feature Importances: \" + str(gbt_model.featureImportances))\n",
    "print(\"Number of Trees: \" + str(gbt_model.getNumTrees))\n",
    "print(\"Max Depth: \" + str(gbt_model.getMaxDepth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c2611dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model\n",
      "Feature Importances: (9,[0,2,3,4,5,8],[0.47256114815476546,0.0010765681447851422,0.14755690887134257,0.00324538948461812,0.0011726078266356206,0.37438737751785306])\n",
      "Max Depth: <bound method _DecisionTreeParams.getMaxDepth of DecisionTreeClassificationModel: uid=DecisionTreeClassifier_60a49c0fa406, depth=5, numNodes=35, numClasses=2, numFeatures=9>\n",
      "Max Bins: <bound method _DecisionTreeParams.getMaxBins of DecisionTreeClassificationModel: uid=DecisionTreeClassifier_60a49c0fa406, depth=5, numNodes=35, numClasses=2, numFeatures=9>\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"is_fraud\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(fraudTrain)\n",
    "print(\"Decision Tree model\")\n",
    "print(\"Feature Importances: \" + str(dt_model.featureImportances))\n",
    "print(\"Max Depth: \" + str(dt_model.getMaxDepth))\n",
    "print(\"Max Bins: \" + str(dt_model.getMaxBins)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e0f53c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron model\n",
      "Weights: [0.3441669510279775,0.5335037792349232,-0.4649653548044888,-0.4236094480668578,0.6296651943077293,-0.12741048585107992,0.0005095617636667882,-0.045905564907101105,0.11947031071660863,0.2485883149683549,0.15585591205861324,-0.07123722944094106,0.047496929201056005,0.20195576205316712,-0.5665286642974072,0.27019557293097013,-0.5052809630172387,0.029538126482082944,0.14628523185909437,0.05314699227989491,-0.4471885349114361,0.5670443162514412,-0.151879115072343,-0.036047501250621984,0.6404111664720772,0.6349218121865925,0.6646456069408733,0.5606466870687726,0.08740783196628292,0.4751112307131016,-0.7379563329316778,0.4276206507691594,0.42663730231519664,0.17538638149751065,0.2602937182915073,-0.681807466962251,0.501189586992898,-0.6522285649928932,-0.6158192800855594,0.2980000990228621,-0.015371358382584965,0.22455673241012356,0.06066686709947403,-0.4366485773618715,-0.19396258428123261,0.5971140007519652,-0.7750711052584455,0.6148142856822143,-0.10619639457908114,-0.4205787989088426,-0.7236108695091366,0.05921649465508446,0.5332243798693553,-0.13859865248379868,-0.7573671668291032,-0.11008608266903448,0.6068070218593221,0.7656244363878444,0.555495658650837,-0.6387073766199945,-0.7583824648776658,0.031446618569514584,-0.7310455997603675,0.6840629891534449,0.387532630797077,0.33894225276670725,0.6101614823978155,-0.13050796758491665,0.15679795598993143,0.40371676972445797,0.007970243982482325,0.6409168226319832,0.5068780572399733,0.27200951695040027,0.06799324535867839,-0.5344047421138702,0.6918435132990761,-0.4044287228620502,0.2142549393637775,-0.4618394865551796,-0.27300074953498416,-0.5738938079514485,-0.4735054454417682,0.13689613644948104,0.7746663141727059,-0.20959133586032155,0.5542645269351335,-0.7291212389527341,-0.7114754495803278,0.6812964575448933,0.7489094838694172,0.7327616483475157,-0.6705476973547855,0.4474291668895285,0.4835730920893007,0.09125156925150983,0.13882776262217314,-0.7809412357437985,-0.27723687934537117,-0.6229862144653787,0.533471938664452,-0.07105291873249918,0.6942249383515213,0.08613484128239955,0.6021377782452572,0.5291515350479964,0.20797084558912293,-0.22106960824808566,0.5224442377338714,0.6994708867422076,0.2068405094958992,-0.5958007416358503,-0.13452650845753458,0.840060567109155,-0.25517629843723666,-0.07933359047643887,-0.5148560417539713,0.08462447548225897,0.01973648413478458,-0.07044208232539072,-0.7212324406591579,0.600620721003483,0.6227031512443382,-0.1412097055797373,-0.08864910537506207,-0.47023725653685355,0.7174629351838626,0.5514061337327003,0.10545948423071844,0.6050559300714478,0.31795273336814267,-0.7203513057759688,0.5319496031525104,-0.5185721378687602,0.45830564826844733,0.3789687161142224,-0.5531072962385144,0.23991218088259578,0.26272833765547743,0.5633789379257211,-0.5295989196109124,-0.6645132648270085,-0.6749236388207911,0.1396011029748998,0.5259021764162141,0.07747332583772726,-0.5080177157409376,0.4380983957823084,-0.4237591732559696,-0.06861012972680479,-0.1697928841118545,0.16123602003557977,0.6253212581559916,0.31760313277232394,0.17394247300316348,1.404180285693758,0.4417222674748471,-0.027237093040028557,0.649308619300322,0.7560594767521851,0.6660450543608183,1.2693168870542524,-0.6925733070291545,1.1013930682149358,-1.455159606093037,0.5525543391278044,-0.04422074343523665]\n",
      "Number of Layers: <bound method _MultilayerPerceptronParams.getLayers of MultilayerPerceptronClassificationModel: uid=MultilayerPerceptronClassifier_4db1f6fe1675, numLayers=4, numClasses=2, numFeatures=9>\n",
      "Block Size: <bound method HasBlockSize.getBlockSize of MultilayerPerceptronClassificationModel: uid=MultilayerPerceptronClassifier_4db1f6fe1675, numLayers=4, numClasses=2, numFeatures=9>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Layers: input layer (9 features), 2 hidden layers (10, 5), output (2 classes)\n",
    "mlp = MultilayerPerceptronClassifier(labelCol=\"is_fraud\", featuresCol=\"features\",\n",
    "                                     layers=[9, 10, 5, 2], blockSize=128, seed=1234, maxIter=100)\n",
    "mlp_model = mlp.fit(fraudTrain)\n",
    "print(\"Multilayer Perceptron model\")\n",
    "print(\"Weights: \" + str(mlp_model.weights))\n",
    "print(\"Number of Layers: \" + str(mlp_model.getLayers))\n",
    "print(\"Block Size: \" + str(mlp_model.getBlockSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "97259390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM model\n",
      "Coefficients: [4.1952552040777895e-08,-0.0001453959608717851,5.826615416237605e-09,2.3096355950573977e-13,-1.6902262282342196e-14,0.00014546223392997748,6.363476259749399e-09,-2.342326498762409e-15,-5.2402358427546885e-08]\n",
      "Intercept: -1.0001217234451034\n",
      "Max Iterations: <bound method HasMaxIter.getMaxIter of LinearSVCModel: uid=LinearSVC_a84789748cee, numClasses=2, numFeatures=9>\n",
      "Reg Param: <bound method HasRegParam.getRegParam of LinearSVCModel: uid=LinearSVC_a84789748cee, numClasses=2, numFeatures=9>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "svm = LinearSVC(labelCol=\"is_fraud\", featuresCol=\"features\")\n",
    "svm_model = svm.fit(fraudTrain)\n",
    "print(\"Linear SVM model\")\n",
    "print(\"Coefficients: \" + str(svm_model.coefficients))\n",
    "print(\"Intercept: \" + str(svm_model.intercept))\n",
    "print(\"Max Iterations: \" + str(svm_model.getMaxIter))\n",
    "print(\"Reg Param: \" + str(svm_model.getRegParam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "65e354d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: \n",
      "Logistic Regression AUC: 0.8458164653013038\n",
      "Random Forest AUC: 0.9165189240339087\n",
      "GBT AUC: 0.9850874688650666\n",
      "Decision Tree AUC: 0.6384902183794472\n",
      "MLP AUC: 0.5\n",
      "SVM AUC: 0.5628041815631913\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"is_fraud\")\n",
    "print(\"Model Evaluation: \")\n",
    "print(\"Logistic Regression AUC:\", evaluator.evaluate(lr_model.transform(fraudTest)))\n",
    "print(\"Random Forest AUC:\", evaluator.evaluate(rf_model.transform(fraudTest)))\n",
    "print(\"GBT AUC:\", evaluator.evaluate(gbt_model.transform(fraudTest)))\n",
    "print(\"Decision Tree AUC:\", evaluator.evaluate(dt_model.transform(fraudTest)))\n",
    "print(\"MLP AUC:\", evaluator.evaluate(mlp_model.transform(fraudTest)))\n",
    "print(\"SVM AUC:\", evaluator.evaluate(svm_model.transform(fraudTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "007e18e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Evaluation:\n",
      "AUC: 0.8458\n",
      "Precision: 0.9961\n",
      "Recall: 0.9994\n",
      "F1 Score: 0.9939\n",
      "\n",
      "Random Forest Evaluation:\n",
      "AUC: 0.9165\n",
      "Precision: 0.9961\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9942\n",
      "\n",
      "Gradient Boosted Trees Evaluation:\n",
      "AUC: 0.9851\n",
      "Precision: 0.9968\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9956\n",
      "\n",
      "Decision Tree Evaluation:\n",
      "AUC: 0.6385\n",
      "Precision: 0.9978\n",
      "Recall: 0.9987\n",
      "F1 Score: 0.9964\n",
      "\n",
      "MLP Classifier Evaluation:\n",
      "AUC: 0.5000\n",
      "Precision: 0.9961\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9942\n",
      "\n",
      "Linear SVM Evaluation:\n",
      "AUC: 0.5628\n",
      "Precision: 0.9961\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9942\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "def evaluate_model(model, name):\n",
    "    predictions = model.transform(fraudTest)\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "    precision = precision_evaluator.evaluate(predictions)\n",
    "    recall = recall_evaluator.evaluate(predictions)\n",
    "    f1 = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "evaluate_model(lr_model, \"Logistic Regression\")\n",
    "evaluate_model(rf_model, \"Random Forest\")\n",
    "evaluate_model(gbt_model, \"Gradient Boosted Trees\")\n",
    "evaluate_model(dt_model, \"Decision Tree\")\n",
    "evaluate_model(mlp_model, \"MLP Classifier\")\n",
    "evaluate_model(svm_model, \"Linear SVM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "train_pd = fraudTrain.select(\"features\", \"is_fraud\").toPandas()\n",
    "test_pd = fraudTest.select(\"features\", \"is_fraud\").toPandas()\n",
    "\n",
    "import numpy as np\n",
    "X_train = np.array([row.toArray() for row in train_pd['features']])\n",
    "y_train = train_pd['is_fraud']\n",
    "X_test = np.array([row.toArray() for row in test_pd['features']])\n",
    "y_test = test_pd['is_fraud']\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=50, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"XGBoost AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "# xgb = SparkXGBClassifier(label_col=\"is_fraud\", features_col=\"features\", num_round=20)\n",
    "# xgb_model = xgb.fit(fraudTrain)\n",
    "# xgb_predictions = xgb_model.transform(fraudTest)\n",
    "\n",
    "# # Evaluate\n",
    "# evaluate_model(xgb_model, \"XGBoost Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73354535",
   "metadata": {},
   "source": [
    "User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c232cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_input = {\n",
    "    'amt': 100.0,\n",
    "    'lat': 37.7749,\n",
    "    'long': -122.4194,\n",
    "    'city_pop': 50000,\n",
    "    'unix_time': 1325376018,\n",
    "    'merch_lat': 37.0,\n",
    "    'merch_long': -122.0,\n",
    "    'trans_date_ts': 1577836800,\n",
    "    'category': 'misc_pos'\n",
    "}\n",
    "\n",
    "input_df = spark.createDataFrame([Row(**user_input)])\n",
    "input_df = indexer_model.transform(input_df)\n",
    "input_df = assembler.transform(input_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98dd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction:\n",
      "+----------+--------------------+\n",
      "|prediction|         probability|\n",
      "+----------+--------------------+\n",
      "|       1.0|[2.55771086293919...|\n",
      "+----------+--------------------+\n",
      "\n",
      "Random Forest Prediction:\n",
      "+----------+--------------------+\n",
      "|prediction|         probability|\n",
      "+----------+--------------------+\n",
      "|       0.0|[0.99671160260851...|\n",
      "+----------+--------------------+\n",
      "\n",
      "GBT Prediction:\n",
      "+----------+--------------------+\n",
      "|prediction|         probability|\n",
      "+----------+--------------------+\n",
      "|       0.0|[0.95641898530100...|\n",
      "+----------+--------------------+\n",
      "\n",
      "Decision Tree Prediction:\n",
      "+----------+--------------------+\n",
      "|prediction|         probability|\n",
      "+----------+--------------------+\n",
      "|       0.0|[0.99966359847532...|\n",
      "+----------+--------------------+\n",
      "\n",
      "MLP Prediction:\n",
      "+----------+--------------------+\n",
      "|prediction|         probability|\n",
      "+----------+--------------------+\n",
      "|       0.0|[0.99421319048786...|\n",
      "+----------+--------------------+\n",
      "\n",
      "SVM Prediction:\n",
      "+----------+--------------------+\n",
      "|prediction|       rawPrediction|\n",
      "+----------+--------------------+\n",
      "|       0.0|[1.00025584318916...|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Prediction:\")\n",
    "lr_pred=lr_model.transform(input_df).select(\"prediction\", \"probability\")\n",
    "lr_pred.show()\n",
    "\n",
    "print(\"Random Forest Prediction:\")\n",
    "rf_pred=rf_model.transform(input_df).select(\"prediction\", \"probability\")\n",
    "rf_pred.show()\n",
    "\n",
    "print(\"GBT Prediction:\")\n",
    "gbt_pred=gbt_model.transform(input_df).select(\"prediction\", \"probability\")\n",
    "gbt_pred.show()\n",
    "\n",
    "print(\"Decision Tree Prediction:\")\n",
    "dt_pred=dt_model.transform(input_df).select(\"prediction\", \"probability\")\n",
    "dt_pred.show()\n",
    "\n",
    "print(\"MLP Prediction:\")\n",
    "mlp_pred=mlp_model.transform(input_df).select(\"prediction\", \"probability\")\n",
    "mlp_pred.show()\n",
    "\n",
    "print(\"SVM Prediction:\")\n",
    "svm_pred=svm_model.transform(input_df).select(\"prediction\", \"rawPrediction\")\n",
    "svm_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c56062",
   "metadata": {},
   "source": [
    "Xg Boost Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Prediction for User Input: 0\n",
      "XGBoost Probability of no Fraud: 0.9994\n"
     ]
    }
   ],
   "source": [
    "user_features = np.array([row.features.toArray() for row in input_df.select(\"features\").collect()])\n",
    "\n",
    "xgb_user_pred = int(model.predict(user_features)[0])\n",
    "xgb_user_prob = float(model.predict_proba(user_features)[0][1])\n",
    "\n",
    "print(f\"XGBoost Prediction for User Input: {xgb_user_pred}\")\n",
    "print(f\"XGBoost Probability of no Fraud: {1 - xgb_user_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled (majority voting) prediction: 0\n"
     ]
    }
   ],
   "source": [
    "# Ensemble => for Prediction \n",
    "preds = [\n",
    "    lr_pred.first()[0],\n",
    "    rf_pred.first()[0],\n",
    "    gbt_pred.first()[0],\n",
    "    dt_pred.first()[0],\n",
    "    mlp_pred.first()[0],\n",
    "    svm_pred.first()[0],\n",
    "    xgb_user_pred,\n",
    "]\n",
    "final_vote = round(sum(preds) / len(preds))\n",
    "print(f\"Ensembled (majority voting) prediction: {final_vote}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6094b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled Probability of Fraud: 0.8246\n",
      "Ensembled (Majority Voting) Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "#all floats\n",
    "preds = [\n",
    "    # float(lr_pred.first()[1][0]),     \n",
    "    # Logistic Regression prob\n",
    "    float(rf_pred.first()[1][0]),     \n",
    "    # Random Forest prob\n",
    "    float(gbt_pred.first()[1][0]),    \n",
    "    # Gradient Boosted Tree prob\n",
    "    float(dt_model.first()[1][0]),    \n",
    "    # Decision Tree prob\n",
    "    float(mlp_pred.first()[1][0]),    \n",
    "    # MLP prob\n",
    "    float(svm_pred.first()[1][0]),    \n",
    "    # SVM prob\n",
    "    float(xgb_user_prob)\n",
    "]\n",
    "\n",
    "final_prob = sum(preds) / len(preds)\n",
    "final_vote = round(final_prob)\n",
    "\n",
    "print(f\"Ensembled Probability of Fraud: {final_prob:.4f}\")\n",
    "print(f\"Ensembled (Majority Voting) Prediction: {final_vote}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84955630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34574c60",
   "metadata": {},
   "source": [
    "Saving the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b934b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:/hadoop\"\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:/hadoop/bin\"\n",
    "\n",
    "\n",
    "lr_model.write().overwrite().save(\"models/lr_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ef149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Set the HADOOP_HOME environment variable\n",
    "# os.environ[\"HADOOP_HOME\"] = \"C:/hadoop\"\n",
    "# os.environ[\"PATH\"] += os.pathsep + \"C:/hadoop/bin\"\n",
    "\n",
    "# # Now start Spark session after setting the environment variables\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"CreditCardFraudDetection\").getOrCreate()\n",
    "\n",
    "# # Now you should be able to save your models\n",
    "# lr_model.write().overwrite().save(\"models/lr_model\")\n",
    "# rf_model.write().overwrite().save(\"models/rf_model\")\n",
    "# gbt_model.write().overwrite().save(\"models/gbt_model\")\n",
    "# dt_model.write().overwrite().save(\"models/dt_model\")\n",
    "# mlp_model.write().overwrite().save(\"models/mlp_model\")\n",
    "# svm_model.write().overwrite().save(\"models/svm_model\")\n",
    "\n",
    "# # Preprocessing stages\n",
    "# indexer_model.write().overwrite().save(\"models/indexer_model\")\n",
    "# assembler.write().overwrite().save(\"models/assembler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save Spark MLlib models\n",
    "# lr_model.save(\"models/lr_model\")\n",
    "# rf_model.save(\"models/rf_model\")\n",
    "# gbt_model.save(\"models/gbt_model\")\n",
    "# dt_model.save(\"models/dt_model\")\n",
    "# mlp_model.save(\"models/mlp_model\")\n",
    "# svm_model.save(\"models/svm_model\")\n",
    "\n",
    "# # Save preprocessing stages\n",
    "# indexer_model.write().overwrite().save(\"models/indexer_model\")\n",
    "# assembler.write().overwrite().save(\"models/assembler\")\n",
    "\n",
    "# # Save XGBoost model\n",
    "# import joblib\n",
    "# joblib.dump(model, \"models/xgb_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724aef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.5'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d73d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled Probability of Fraud: 0.8246\n",
      "Ensembled (Majority Voting) Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "#all floats\n",
    "preds = [\n",
    "    # float(lr_pred.first()[1][0]),     \n",
    "    # Logistic Regression prob\n",
    "    float(rf_pred.first()[1][0]),     \n",
    "    # Random Forest prob\n",
    "    float(gbt_pred.first()[1][0]),    \n",
    "    # Gradient Boosted Tree prob\n",
    "    float(dt_model.first()[1][0]),    \n",
    "    # Decision Tree prob\n",
    "    float(mlp_pred.first()[1][0]),    \n",
    "    # MLP prob\n",
    "    float(svm_pred.first()[1][0]),    \n",
    "    # SVM prob\n",
    "    float(xgb_user_prob)\n",
    "]\n",
    "\n",
    "final_prob = sum(preds) / len(preds)\n",
    "final_vote = round(final_prob)\n",
    "\n",
    "print(f\"Ensembled Probability of Fraud: {final_prob:.4f}\")\n",
    "print(f\"Ensembled (Majority Voting) Prediction: {final_vote}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
