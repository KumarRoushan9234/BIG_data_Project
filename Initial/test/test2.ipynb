{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "008d09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import NumericType\n",
    "from pyspark.sql.functions import col, count, when, unix_timestamp\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8159d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('CreditCardFraudEDA').getOrCreate()\n",
    "fraudTrain = spark.read.csv('fraudTrain.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc676804",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTest = spark.read.csv(\"fraudTest.csv\", header=True, inferSchema=True)\n",
    "drop_cols = ['_c0', 'cc_num', 'first', 'last', 'gender', 'street', 'city', 'state',\n",
    "             'zip', 'job', 'dob', 'trans_num', 'merchant']\n",
    "\n",
    "fraudTest = fraudTest.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d99fcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTest = fraudTest.withColumn(\"trans_date_ts\", unix_timestamp(\"trans_date_trans_time\")).drop(\"trans_date_trans_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e687a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- trans_date_trans_time: timestamp (nullable = true)\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- dob: date (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      "\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
      "|_c0|trans_date_trans_time|          cc_num|            merchant|     category|   amt|    first|   last|gender|              street|          city|state|  zip|    lat|     long|city_pop|                 job|       dob|           trans_num| unix_time|         merch_lat| merch_long|is_fraud|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
      "|  0|  2019-01-01 00:00:18|2703186189652095|fraud_Rippin, Kub...|     misc_net|  4.97| Jennifer|  Banks|     F|      561 Perry Cove|Moravian Falls|   NC|28654|36.0788| -81.1781|    3495|Psychologist, cou...|1988-03-09|0b242abb623afc578...|1325376018|         36.011293| -82.048315|       0|\n",
      "|  1|  2019-01-01 00:00:44|    630423337322|fraud_Heller, Gut...|  grocery_pos|107.23|Stephanie|   Gill|     F|43039 Riley Green...|        Orient|   WA|99160|48.8878|-118.2105|     149|Special education...|1978-06-21|1f76529f857473494...|1325376044|49.159046999999994|-118.186462|       0|\n",
      "|  2|  2019-01-01 00:00:51|  38859492057661|fraud_Lind-Buckridge|entertainment|220.11|   Edward|Sanchez|     M|594 White Dale Su...|    Malad City|   ID|83252|42.1808| -112.262|    4154|Nature conservati...|1962-01-19|a1a22d70485983eac...|1325376051|         43.150704|-112.154481|       0|\n",
      "|  3|  2019-01-01 00:01:16|3534093764340240|fraud_Kutch, Herm...|gas_transport|  45.0|   Jeremy|  White|     M|9443 Cynthia Cour...|       Boulder|   MT|59632|46.2306|-112.1138|    1939|     Patent attorney|1967-01-12|6b849c168bdad6f86...|1325376076|         47.034331|-112.561071|       0|\n",
      "|  4|  2019-01-01 00:03:06| 375534208663984| fraud_Keeling-Crist|     misc_pos| 41.96|    Tyler| Garcia|     M|    408 Bradley Rest|      Doe Hill|   VA|24433|38.4207| -79.4629|      99|Dance movement ps...|1986-03-28|a41d7549acf907893...|1325376186|         38.674999| -78.632459|       0|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o821.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 437.0 failed 1 times, most recent failure: Lost task 9.0 in stage 437.0 (TID 4110) (10.12.70.111 executor driver): java.io.FileNotFoundException: C:\\Users\\hp\\AppData\\Local\\Temp\\blockmgr-09fbcc92-ee50-479a-8295-22be4934a6e7\\25\\temp_shuffle_d3c65b5b-05c5-4f5a-9ebb-3eea8475d2da (The system cannot find the path specified)\r\n\tat java.base/java.io.FileOutputStream.open0(Native Method)\r\n\tat java.base/java.io.FileOutputStream.open(FileOutputStream.java:295)\r\n\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:236)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:147)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:167)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:330)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\hp\\AppData\\Local\\Temp\\blockmgr-09fbcc92-ee50-479a-8295-22be4934a6e7\\25\\temp_shuffle_d3c65b5b-05c5-4f5a-9ebb-3eea8475d2da (The system cannot find the path specified)\r\n\tat java.base/java.io.FileOutputStream.open0(Native Method)\r\n\tat java.base/java.io.FileOutputStream.open(FileOutputStream.java:295)\r\n\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:236)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:147)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:167)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:330)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fraudTrain\u001b[38;5;241m.\u001b[39mprintSchema()\n\u001b[0;32m      2\u001b[0m fraudTrain\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mfraudTrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o821.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 437.0 failed 1 times, most recent failure: Lost task 9.0 in stage 437.0 (TID 4110) (10.12.70.111 executor driver): java.io.FileNotFoundException: C:\\Users\\hp\\AppData\\Local\\Temp\\blockmgr-09fbcc92-ee50-479a-8295-22be4934a6e7\\25\\temp_shuffle_d3c65b5b-05c5-4f5a-9ebb-3eea8475d2da (The system cannot find the path specified)\r\n\tat java.base/java.io.FileOutputStream.open0(Native Method)\r\n\tat java.base/java.io.FileOutputStream.open(FileOutputStream.java:295)\r\n\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:236)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:147)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:167)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:330)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\hp\\AppData\\Local\\Temp\\blockmgr-09fbcc92-ee50-479a-8295-22be4934a6e7\\25\\temp_shuffle_d3c65b5b-05c5-4f5a-9ebb-3eea8475d2da (The system cannot find the path specified)\r\n\tat java.base/java.io.FileOutputStream.open0(Native Method)\r\n\tat java.base/java.io.FileOutputStream.open(FileOutputStream.java:295)\r\n\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:236)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:147)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:167)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:330)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\n"
     ]
    }
   ],
   "source": [
    "fraudTrain.printSchema()\n",
    "fraudTrain.show(5)\n",
    "fraudTrain.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric :  ['_c0', 'cc_num', 'amt', 'zip', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud']\n",
      "Others :  ['trans_date_trans_time', 'merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'job', 'dob', 'trans_num']\n"
     ]
    }
   ],
   "source": [
    "schema = fraudTrain.schema.fields\n",
    "column_types = {\"numeric\": [], \"others\": []}\n",
    "for field in schema:\n",
    "    if isinstance(field.dataType, NumericType):\n",
    "        column_types[\"numeric\"].append(field.name)\n",
    "    else:\n",
    "        column_types[\"others\"].append(field.name)\n",
    "\n",
    "print(\"Numeric : \", column_types[\"numeric\"])\n",
    "print(\"Others : \", column_types[\"others\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2e8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+------+--------+--------+---+-----+----+------+------+----+-----+---+---+----+--------+---+---+---------+---------+---------+----------+--------+\n",
      "|_c0|trans_date_trans_time|cc_num|merchant|category|amt|first|last|gender|street|city|state|zip|lat|long|city_pop|job|dob|trans_num|unix_time|merch_lat|merch_long|is_fraud|\n",
      "+---+---------------------+------+--------+--------+---+-----+----+------+------+----+-----+---+---+----+--------+---+---+---------+---------+---------+----------+--------+\n",
      "|  0|                    0|     0|       0|       0|  0|    0|   0|     0|     0|   0|    0|  0|  0|   0|       0|  0|  0|        0|        0|        0|         0|       0|\n",
      "+---+---------------------+------+--------+--------+---+-----+----+------+------+----+-----+---+---+----+--------+---+---+---------+---------+---------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fraudTrain.select([count(when(col(c).isNull(), c)).alias(c) for c in fraudTrain.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8a965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+-------+---------+--------+----------+------------------+-----------+--------+-------------+\n",
      "|     category|   amt|    lat|     long|city_pop| unix_time|         merch_lat| merch_long|is_fraud|trans_date_ts|\n",
      "+-------------+------+-------+---------+--------+----------+------------------+-----------+--------+-------------+\n",
      "|     misc_net|  4.97|36.0788| -81.1781|    3495|1325376018|         36.011293| -82.048315|       0|   1546281018|\n",
      "|  grocery_pos|107.23|48.8878|-118.2105|     149|1325376044|49.159046999999994|-118.186462|       0|   1546281044|\n",
      "|entertainment|220.11|42.1808| -112.262|    4154|1325376051|         43.150704|-112.154481|       0|   1546281051|\n",
      "|gas_transport|  45.0|46.2306|-112.1138|    1939|1325376076|         47.034331|-112.561071|       0|   1546281076|\n",
      "|     misc_pos| 41.96|38.4207| -79.4629|      99|1325376186|         38.674999| -78.632459|       0|   1546281186|\n",
      "+-------------+------+-------+---------+--------+----------+------------------+-----------+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+--------------------+\n",
      "|summary|     category|              amt|              lat|              long|         city_pop|           unix_time|         merch_lat|        merch_long|            is_fraud|       trans_date_ts|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+--------------------+\n",
      "|  count|      1296675|          1296675|          1296675|           1296675|          1296675|             1296675|           1296675|           1296675|             1296675|             1296675|\n",
      "|   mean|         NULL|70.35103545607046|38.53762161490217|-90.22633537864573|88824.44056297839|1.3492436367261226E9|38.537338044699666|-90.22646479897256|0.005788651743883394|1.5700870480702143E9|\n",
      "| stddev|         NULL|160.3160385715277|5.075808438803937|13.759076946486305|301956.3606887509|1.2841278423361162E7|  5.10978836967917|13.771090564792418| 0.07586268973125161| 1.285544828225918E7|\n",
      "|    min|entertainment|              1.0|          20.0271|         -165.6723|               23|          1325376018|         19.027785|       -166.671242|                   0|          1546281018|\n",
      "|    max|       travel|          28948.9|          66.6933|          -67.9503|          2906700|          1371816817|         67.510267|        -66.950902|                   1|          1592721817|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['_c0', 'cc_num', 'first', 'last', 'gender', 'street', 'city', 'state',\n",
    "             'zip', 'job', 'dob', 'trans_num', 'merchant']\n",
    "data = fraudTrain.drop(*drop_cols)\n",
    "\n",
    "data = data.withColumn(\"trans_date_ts\", unix_timestamp(\"trans_date_trans_time\")).drop(\"trans_date_trans_time\")\n",
    "\n",
    "data.show(5)\n",
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf92067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|is_fraud|\n",
      "+--------------------+--------+\n",
      "|[4.97,36.0788,-81...|       0|\n",
      "|[107.23,48.8878,-...|       0|\n",
      "|[220.11,42.1808,-...|       0|\n",
      "|[45.0,46.2306,-11...|       0|\n",
      "|[41.96,38.4207,-7...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_col = \"category\"\n",
    "indexer = StringIndexer(inputCol=cat_col, outputCol=\"category_index\", handleInvalid='keep')\n",
    "indexer_model = indexer.fit(data)\n",
    "data_indexed = indexer_model.transform(data)\n",
    "\n",
    "feature_cols = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long', 'trans_date_ts', 'category_index']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "final_data = assembler.transform(data_indexed).select(\"features\", \"is_fraud\")\n",
    "\n",
    "final_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f144c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"is_fraud\", featuresCol=\"features\")\n",
    "lr_model = lr.fit(train_data)\n",
    "lr_preds = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"is_fraud\", featuresCol=\"features\", numTrees=50)\n",
    "rf_model = rf.fit(train_data)\n",
    "rf_preds = rf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229bb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg AUC: 0.8636127971215811\n",
      "Random Forest AUC: 0.9140737744298402\n",
      "GBT AUC: 0.9866982328734673\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(labelCol=\"is_fraud\", featuresCol=\"features\", maxIter=20)\n",
    "gbt_model = gbt.fit(train_data)\n",
    "gbt_preds = gbt_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"is_fraud\")\n",
    "print(\"LogReg AUC:\", evaluator.evaluate(lr_preds))\n",
    "print(\"Random Forest AUC:\", evaluator.evaluate(rf_preds))\n",
    "print(\"GBT AUC:\", evaluator.evaluate(gbt_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61315a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|prediction|         probability|\n",
      "+----------+--------------------+\n",
      "|       0.0|[0.99738403679790...|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = {\n",
    "    'amt': 100.0,\n",
    "    'lat': 37.7749,\n",
    "    'long': -122.4194,\n",
    "    'city_pop': 50000,\n",
    "    'unix_time': 1325376018,\n",
    "    'merch_lat': 37.0,\n",
    "    'merch_long': -122.0,\n",
    "    'trans_date_ts': 1577836800,\n",
    "    'category': 'misc_pos'\n",
    "}\n",
    "\n",
    "input_df = spark.createDataFrame([Row(**user_input)])\n",
    "input_df = indexer_model.transform(input_df)\n",
    "input_df = assembler.transform(input_df)\n",
    "prediction = rf_model.transform(input_df).select(\"prediction\", \"probability\")\n",
    "prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0aa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0a554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
